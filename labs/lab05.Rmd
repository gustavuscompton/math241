---
title: "Lab 5"
#author: "Gustavus Compton"
date: "Math 241, Week 6"
output:
  pdf_document
urlcolor: blue
---

```{r setup, include=FALSE}
# Do not modify this chunk.
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)


```

```{r}
# Put all necessary libraries here
library(tidyverse)
library(rnoaa)
library(rvest)
library(httr)
```



## Due: Friday, March 1st at 8:30am

## Goals of this lab

1. Practice grabbing data from the internet.
1. Learn to navigate new R packages.
1. Grab data from an API (either directly or using an API wrapper).
1. Scrape data from the web.


## Potential API Wrapper Packages

## Problem 1: Predicting the ~~Un~~predictable: Portland Weather

In this problem let's get comfortable with extracting data from the National Oceanic and Atmospheric Administration's (NOAA) API via the R API wrapper package `rnoaa`.

You can find more information about the datasets and variables [here](https://www.ncdc.noaa.gov/homr/reports).

```{r, echo=FALSE}
# Don't forget to install it first!
#dependencies needed
library(rnoaa)
```

a. First things first, go to [this NOAA website](https://www.ncdc.noaa.gov/cdo-web/token) to get a key emailed to you.  Then insert your key below:

```{r, eval = T, echo= FALSE}
options(noaakey = "gcAUuidnUDbKNfieITeIKVtnNNutCbHS")
```



b. From the National Climate Data Center (NCDC) data, use the following code to grab the stations in Multnomah County. How many stations are in Multnomah County?

```{r, eval = T}
stations <- ncdc_stations(datasetid = "GHCND", 
                          locationid = "FIPS:41051")

mult_stations <- stations$data

mult_stations %>%
  summarize(multnomahstations = n())
```



c. January was not so rainy this year, was it?  Let's grab the precipitation data for site `GHCND:US1ORMT0006` for this past January.

```{r, eval = T}
# First fill-in and run to following to determine the
# datatypeid
ncdc_datatypes(datasetid = "GHCND",
               stationid = "GHCND:US1ORMT0006")



# Now grab the data using ncdc()
precip_se_pdx <- ncdc(datasetid = "GHCND",
               stationid = "GHCND:US1ORMT0006",
               startdate = "2024-01-01",
               enddate = "2024-02-01")


```

d.  What is the class of `precip_se_dpx`?  Grab the data frame nested in `precip_se_dpx` and call it `precip_se_dpx_data`.

```{r}
class(precip_se_pdx)

precip_se_pdx_data <- precip_se_pdx$data


```


e. Use `ymd_hms()` in the package `lubridate` to wrangle the date column into the correct format.

```{r}
precip_se_pdx_data$date <- ymd_hms(precip_se_pdx_data$date)
```


f. Plot the precipitation data for this site in Portland over time.  Rumor has it that we had only one day where it didn't rain.  Is that true?

```{r}
precip_se_pdx_data %>%
  ggplot(aes(x = date, y = value, fill = datatype)) +
  geom_col()
```
Not true. This dataset only includes up to January 13th but even with that missing data we can see that it did not rain for several days at the beginning of the month.

g. (Bonus) Adapt the code to create a visualization that compares the precipitation data for January over the the last four years.  Do you notice any trend over time?

```{r}
#2020
precip_se_pdx_2020 <- ncdc(datasetid = "GHCND",
               stationid = "GHCND:US1ORMT0006",
               startdate = "2020-01-01",
               enddate = "2020-02-01")

precip_se_pdx_2020_data <- precip_se_pdx_2020$data

precip_se_pdx_2020_data$date <- ymd_hms(precip_se_pdx_2020_data$date)
#2021
precip_se_pdx_2021 <- ncdc(datasetid = "GHCND",
               stationid = "GHCND:US1ORMT0006",
               startdate = "2021-01-01",
               enddate = "2021-02-01")

precip_se_pdx_2021_data <- precip_se_pdx_2021$data

precip_se_pdx_2021_data$date <- ymd_hms(precip_se_pdx_2021_data$date)
#2022
precip_se_pdx_2022 <- ncdc(datasetid = "GHCND",
               stationid = "GHCND:US1ORMT0006",
               startdate = "2022-01-01",
               enddate = "2022-02-01")

precip_se_pdx_2022_data <- precip_se_pdx_2022$data

precip_se_pdx_2022_data$date <- ymd_hms(precip_se_pdx_2022_data$date)
#2023
precip_se_pdx_2023 <- ncdc(datasetid = "GHCND",
               stationid = "GHCND:US1ORMT0006",
               startdate = "2023-01-01",
               enddate = "2023-02-01")

precip_se_pdx_2023_data <- precip_se_pdx_2023$data

precip_se_pdx_2023_data$date <- ymd_hms(precip_se_pdx_2023_data$date)

last4years <- precip_se_pdx_data %>% full_join(precip_se_pdx_2023_data)

last4years <- last4years %>% full_join(precip_se_pdx_2022_data)

last4years <- last4years %>% full_join(precip_se_pdx_2021_data)

last4years <- last4years %>% full_join(precip_se_pdx_2020_data)

trying <- last4years %>%
  mutate(year = year(date), newdate = mday(date))

trying %>%
  ggplot(aes(x = newdate, y = value)) +
  geom_col() +
  facet_wrap(~year, ncol = 1)

```



## Problem 2: From API to R 

For this problem I want you to grab web data by either talking to an API directly with `httr` or using an API wrapper.  It must be an API that we have NOT used in class or in Problem 1.

Once you have grabbed the data, do any necessary wrangling to graph it and/or produce some summary statistics. Draw some conclusions from your graph and summary statistics.

### API Wrapper Suggestions for Problem 2

Here are some potential API wrapper packages.  Feel free to use one not included in this list for Problem 2.

* `gtrendsR`: "An interface for retrieving and displaying the information returned online by Google Trends is provided. Trends (number of hits) over the time as well as geographic representation of the results can be displayed."
* [`rfishbase`](https://github.com/ropensci/rfishbase): For the fish lovers
* [`darksky`](https://github.com/hrbrmstr/darksky): For global historical and current weather conditions

```{r}
library(rfishbase)
```

```{r}
salmon <- c("Oncorhynchus tshawytscha", "Salmo salar", "Oncorhynchus keta", "Oncorhynchus kisutch",  "Oncorhynchus masou", "Oncorhynchus gorbuscha", "Oncorhynchus nerka")

selectedfish <- fb_tbl("species") %>% 
  mutate(sci_name = paste(Genus, Species)) %>%
  filter(sci_name %in% salmon)


salmonpredators <- predators(species_list = salmon)


trying2 <- salmonpredators %>%
  group_by(Species) %>%
  group_by(PredatorI) %>%
  mutate(numberofpredators = n())


  trying2 %>%
  ggplot(aes(x = PredatorI, y = numberofpredators)) +
  geom_col() +
  facet_wrap(~Species, ncol = 4) + 
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
    labs(x = "Primary predator type", y = "# of different predator species", title = "Distribution of predator types across different salmon species")
```




## Problem 3: Scraping Reedie Data

Let's see what lovely data we can pull from Reed's own website.  

a. Go to [https://www.reed.edu/ir/success.html](https://www.reed.edu/ir/success.html) and scrape the two tables.

```{r}
url <- "https://www.reed.edu/ir/success.html"

reedtables <- url %>%
  read_html() %>%
  html_nodes(css = "table")

employmenttypetable <- html_table(reedtables[[1]], fill = TRUE)


furtherschoolingtable <- html_table(reedtables[[2]], fill = TRUE)


fellowshipstable <- html_table(reedtables[[3]], fill = TRUE)


```



b. Grab and print out the table that is entitled "GRADUATE SCHOOLS MOST FREQUENTLY ATTENDED BY REED ALUMNI".  Why is this data frame not in a tidy format?
```{r}
print(furtherschoolingtable)
```

The different schools are separated into columns by type of graduate degree. In a tidy data format, this data frame would have two columns: one that's a "school name" and one thats a "degree type". 


c. Wrangle the data into a tidy format. Glimpse the resulting data frame.
```{r}

  furtherschoolingtabletidy <- pivot_longer(furtherschoolingtable, 
                          cols = c(MBAs, JDs, PhDs, MDs), 
                          names_to = "degree_type", 
                          values_to = "school_name")


glimpse(furtherschoolingtabletidy)
```



d. Now grab the "OCCUPATIONAL DISTRIBUTION OF ALUMNI" table and turn it into an appropriate graph.  What conclusions can we draw from the graph?

```{r}
# Hint: Use `parse_number()` within `mutate()` to fix one of the columns
employmenttypetable <- employmenttypetable %>%
rename(employmenttype = X1) %>%
rename(propfalse = X2) %>%
  mutate(prop = as.numeric(sub("%", "", propfalse)))

ggplot(data = employmenttypetable, aes(x = employmenttype, y = prop)) +
  geom_col() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(x = "Area of Employment", y = "Proportion of Reed Graduates")
```



e. Let's now grab the Reed graduation rates over time.  Grab the data from [here](https://www.reed.edu/ir/gradrateshist.html).

```{r}
url2 <- "https://www.reed.edu/ir/gradrateshist.html"
  
  
  gradtablehtml <- url2 %>%
  read_html() %>%
  html_nodes(css = "table")

gradtable <- html_table(gradtablehtml[[1]], fill = TRUE)


```


Do the following to clean up the data:

* Rename the column names.  

```{r,eval = T}
# Hint
colnames(gradtable) <- c("StartYear", "ClassSize", "Fouryeargradrate", "Fiveyeargradrate", "Sixyeargradrate")
```

* Remove any extraneous rows.

```{r, eval = T}
# Hint
fixinggradtable <- gradtable %>%
filter(StartYear != "First-year students who entered fall of...") %>%
  filter(StartYear != "2019") %>%
  filter(StartYear != "2018") %>%
  filter(StartYear != "2017")
```

* Reshape the data so that there are columns for 
    + Entering class year
    + Cohort size
    + Years to graduation
    + Graduation rate
    


* Make sure each column has the correct class.   

```{r}
fixinggradtable2 <- fixinggradtable %>%
  mutate(Fouryearprop = as.numeric(sub("%", "", Fouryeargradrate)), 
         Fiveyearprop = as.numeric(sub("%", "", Fiveyeargradrate)),
         Sixyearprop = as.numeric(sub("%", "", Sixyeargradrate)))

```



f. Create a graph comparing the graduation rates over time and draw some conclusions.

```{r}
fixinggradtable2 %>%
  ggplot(aes(x = StartYear, y = Fouryearprop)) +
  geom_col() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(x = "Freshman class year", y = "Proportion of students who graduate in four years", title = "Four-year graduation rates at Reed College") 

fixinggradtable2 %>%
  ggplot(aes(x = StartYear, y = Fiveyearprop)) +
  geom_col() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(x = "Freshman class year", y = "Proportion of students who graduate in five years", title = "Five-year graduation rates at Reed College") 

fixinggradtable2 %>%
  ggplot(aes(x = StartYear, y = Sixyearprop)) +
  geom_col() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(x = "Freshman class year", y = "Proportion of students who graduate in six years", title = "Six-year graduation rates at Reed College") 

```

Four-year graduation rates are going up quite a bit over time. Since these proportions are cumulative, we can see in the six-year graduation rates that total proportions of students graduating has increased slightly from ~60% of students in the 1980s to ~80% of students in the 2010s. Alongside this increase in total amount of graduating students is a decrease between four-year graduation rates and six-year graduation rates, which tells us that recently, more students are graduating in four years and are not taking additional time to graduate.

